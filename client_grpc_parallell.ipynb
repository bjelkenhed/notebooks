{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grpc.beta import implementations\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "import tensorflow as tf\n",
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelClient():\n",
    "    \n",
    "    MODEL_HOST = '10.100.241.46'\n",
    "    PORT=8500\n",
    "    \n",
    "    def __init__(self, model_host = MODEL_HOST, port=PORT):\n",
    "        channel = implementations.insecure_channel(model_host, int(port))\n",
    "        stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "        self.stub = stub\n",
    "        \n",
    "    def predict(self, indata):\n",
    "        request = predict_pb2.PredictRequest()\n",
    "        request.model_spec.name = 'model'\n",
    "        request.model_spec.signature_name = 'serving_default'\n",
    "        request.inputs['input'].CopyFrom(tf.contrib.util.make_tensor_proto(indata, shape=indata.shape))\n",
    "        response = self.stub.Predict.future(request, 10.0)  # wait max 5s\n",
    "        return response.result().outputs[\"score\"].float_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_serving/apis/prediction_service_pb2.py:131: DeprecationWarning: beta_create_PredictionService_stub() method is deprecated. This method will be removed in near future versions of TF Serving. Please switch to GA gRPC API in prediction_service_pb2_grpc.\n",
      "  'prediction_service_pb2_grpc.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "modelClient = ModelClient()\n",
    "indata = np.random.randint(100000, size=(5000, 20)).astype(np.float32)\n",
    "\n",
    "indata_batches = []\n",
    "for i in range(200):\n",
    "    indata_batches.append(indata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(indata):\n",
    "    #print(\"Request\", indata.shape)\n",
    "    result = modelClient.predict(indata)\n",
    "    #print(\"Response\", result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 329 ms, sys: 83.9 ms, total: 412 ms\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "pool = ThreadPool(8) \n",
    "\n",
    "%time result = pool.map(make_prediction, indata_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85470.08547008547"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000000 / 11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
